<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Reflection</title>
</head>
<body>
    <body bgcolor="grey">
        <picture>
  <img src="https://magnirealty.com/wp-content/uploads/2023/12/magni_logo_500_300.png" width=300 height=200/>
            <img src="https://drive.google.com/file/d/1rkl3z4i9kmGB8xVd4pRzpdJ6YdKvnHrF/view?usp=drive_link/01.jpg" width=300 height=200" width=300 height=200
</picture>
    <h1>Voice Reflection</h1>
    <div id="output"></div>
    <audio id="audio" controls></audio>
    <script>
        const outputDiv = document.getElementById('output');
        const audioElement = document.getElementById('audio');
        let audioChunks = [];

        // Check if browser supports SpeechRecognition and getUserMedia
        if ('webkitSpeechRecognition' in window && 'getUserMedia' in navigator.mediaDevices) {
            const recognition = new webkitSpeechRecognition();

            recognition.continuous = true; // Keep listening after each recognition
            recognition.interimResults = true; // Show interim results as they are recognized

            recognition.onresult = function(event) {
                const result = event.results[event.results.length - 1][0].transcript;
                outputDiv.innerText = result;

                // Speak the recognized text
                const utterance = new SpeechSynthesisUtterance(result);
                window.speechSynthesis.speak(utterance);
            };

            recognition.onerror = function(event) {
                console.error('Speech recognition error:', event.error);
            };

            recognition.onend = function() {
                // Restart recognition when it ends
                recognition.start();
            };

            // Start recognition
            recognition.start();

            // Start capturing audio stream
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    const mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.ondataavailable = event => {
                        audioChunks.push(event.data);
                    };
                    mediaRecorder.start();

                    // Play captured audio in real-time
                    const audioContext = new AudioContext();
                    const audioSource = audioContext.createMediaStreamSource(stream);
                    audioSource.connect(audioContext.destination);
                })
                .catch(error => {
                    console.error('Error accessing microphone:', error);
                });
        } else {
            outputDiv.innerText = "Your browser doesn't support speech recognition or getUserMedia.";
        }
    </script>
</body>
</html>
